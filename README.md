# Cook-Video_Analysis

Using AI of CV, Analysis Cook-Video like Paik's Cuisine, ë°±ì¢…ì›ì˜ ìš”ë¦¬ ë¹„ì±…

**[Jaechan Jo](mailto:jjc123a@naver.com)**

Multi Media System Lab, Sogang AI Research.

## Sample Results
### Overview
In order to utilize the scattered cooking videos, metadata and section tagging are carried out through an artificial intelligence


- [ğŸ¦† ì—¬ë³´ ì—¬ê¸° ìˆë˜ ë‚´ ì•Œ ëª» ë´¤ì–´ìš”â”‚ë©”ì¶”ë¦¬ì•Œ ì¥ì¡°ë¦¼](https://youtu.be/RmZyxKOUbfs), ë°±ì¢…ì›ì˜ ì¿ í‚¹ë¡œê·¸, ë°±ì¢…ì›ì˜ ìš”ë¦¬ë¹„ì±…

  - Video Image

    <img width="300" alt="teaser" src="./result/img_egg.jpg">
    
  - Output Result

    <img width="430" alt="teaser" src="./result/result_egg.jpg">

  - no residual block

    <img width="600" alt="teaser" src="./result/segment_egg.jpg">
  
  
  
## Model

### 1. Sogang-mmlab
  - [JinhaSong/analysis-engine](https://github.com/JinhaSong/analysis-engine)
      - hidf-engine-food_main : Food obj-detection(Yolov4 + Efficientnet)
      - hidf-engine-scenetext_main : Scene text recognition(CRAFT_pytorch)

### 2. Vision Analysis
  - Classification
    - food classification
>   - **YOLOv4**: MS COCO Dataset (related with food) e.g) 'bowl', â€˜wine glassâ€™, â€˜cupâ€™, â€˜forkâ€™, knifeâ€™, â€˜spoonâ€™â€¦
>   - **EfficinetNet**: AI hub, KIST (ì£¼)íœ´ë¨¼ICT, 2017, [í•œêµ­ ì´ë¯¸ì§€(ìŒì‹)](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=79)

  - Action_recognition
    - [**MMAction2**](https://github.com/open-mmlab/mmaction2)
>  - Kinetics400
>  - label related with food e.g) â€˜cooking eggâ€™, â€˜cooking chickenâ€™, 'breading or breadcrumbing' â€¦

<br/><br/>
### - action_recognition

  - Hyper-parameter description

>   - ```video_path```**(str)**: action_recognition ëŒë¦´ ì˜ìƒ ì£¼ì†Œ e.g) '/home/Cook_Video_Analysis/Dataset/meat.mp4'
>   - ```sav_dir```**(str)**: êµ¬ê°„ ë¶„í• í•œ ì˜ìƒ ì €ì¥í•  ê²½ë¡œ e.g) '/home/Cook_Video_Analysis/Dataset/segment/'
>   - ```config_file```**(str)**: action_recognition config(module) e.g) 'configs/recognition/tsn/tsn_r50_video_inference_1x1x3_100e_kinetics400_rgb.py'
>   - ```checkpoints_file```**(str)**: weight check point ì£¼ì†Œ e.g) 'checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'
>   - ```device```**(str)**: ì‚¬ìš©í•  device e.g) 'cuda:0' or 'cpu'
>   - ```topk```**(int)**: ëª‡ ê°œì˜ ë¹ˆë„ìˆ˜ ìƒìœ„ íƒœê·¸ë¥¼ ë½‘ì„ ê²ƒì¸ì§€ e.g) 3
>   - ```split```**(bool)**: default=False, ì˜ìƒ ë¶„í• ì„ í•  ê²ƒì¸ì§€, Falseì‹œ í†µ ì˜ìƒ ì±„ë¡œ ë¶„ì„ ê²°ê³¼ ë„ì¶œ e.g) False
>   - ```segment_sec```**(int)**: default=None, ëª‡ ì´ˆì”© êµ¬ê°„ ë¶„í• ì„ í•  ê²ƒì¸ì§€ e.g) 10
>   - ```fourcc```**(str)**: default=None, four character code : ì½”ë±, ì••ì¶• ë°©ì‹, ìƒ‰ìƒ, í”½ì…€ í¬ë§· ë“±ì„ ì •ì˜í•˜ëŠ” ì •ìˆ˜ ê°’ e.g) 'mp4v'


## Idea

### 3. Text Analysis
  - Segmentation of Video
    - font_height_to_segmentation
>   - í¸ì§‘ìê°€ í¸ì§‘í•  ë•Œ, **íŠ¹ì • ì¥ë©´ì— íŠ¹ì • ìë§‰**ì„ ì‚¬ìš©í•œë‹¤.
>   - íŠ¹íˆ, **ìë§‰ì˜ ë†’ì´**ê°€ ê³ ìœ í•œ ê°’ìœ¼ë¡œ, ì´ë¥¼ í†µí•´ êµ¬ê°„ ë¶„í•  ë° íƒœê·¸ ëª©ë¡ì„ ìƒì„±í•œë‹¤.
>   - ê±°ê¾¸ë¡œ, í¸ì§‘ì„ í•  ë•Œ, ë¶„í• í•˜ê³ ì í•˜ëŠ” ì§€ì ì—ëŠ” íŠ¹ì •í•œ í¬ê¸°ì˜ ìë§‰ì„ ë‹¬ë„ë¡ í•  ìˆ˜ ìˆë‹¤.


  - Ingredient Tags
    - text_simple_match
>   - filtered by whether they are **completely matched or not**, e.g) 'ë©”ì¶”ë¦¬ì•Œ' == 'ë©”ì¶”ë¦¬ì•Œ : True, 'ë©”ì¹˜ë£¨ì•Œ' != 'ë©”ì¶”ë¦¬ì•Œ': False
>   - matching Ingredient DB (source: ì†ŒìŠ¤ì‚°ì—…í™”ì„¼í„°, [ì‹ì¬ë£Œ DB](https://sauce.foodpolis.kr/home/index.do))

<br/><br/>
### - font_height_to_segmentation

  - Hyper-parameter description

>   - ```data```**(json)**: scene_text_recognition result, e.g) result_30
>   - ```video_name```**(str)**: video name without the file extension like .mp4, e.g) 'bundaegi', 'egg', 'nuddle'
>   - ```score```**(float)**: scentxt_score, e.g) 0.7
>   - ```fh_low```**(int)**: font_height_low, e.g) 125
>   - ```fh_high```**(int)**: font_height_high, e.g) 140
>   - ```freq```**(int)**: frequency of text_bboxes per frame, e.g) 10
>   - ```fps```**(int)**: frame per second, e.g) 30
>   - ```find_range```**(int)**: take text_result for time of find_range from segment start time, e.g) 3


### - text_simple_match

  - Hyper-parameter description

>   - ```data```**(list)**: ì§ˆì˜í•  preprocessed scenetext ë¶„ì„ ê²°ê³¼, e.g) egg_text (= preprocess(data=result_30, score=0.9, video_name='egg', module_name='scenetxt'))
>   - ```db```**(Dataframe)**: ë§¤ì¹­í•  ë°ì´í„° ë² ì´ìŠ¤ e.g) ì‹ì¬ë£Œ ë°ì´í„° ë² ì´ìŠ¤, df (= pd.read_csv('./Dataset/dataset/refined/ingredients.csv', encoding = 'cp949' ))
>   - ```topk```**(int)**: ëª‡ ê°œì˜ ë¹ˆë„ìˆ˜ ìƒìœ„ íƒœê·¸ë¥¼ ë½‘ì„ ê²ƒì¸ì§€ e.g) 5


## Setup

### Docker compose

```docker run --gpus all -itd -e LC_ALL=C.UTF-8 --name cook_video_analysis -v"[gpu server dir]":/workspace/ -p 22000:8888 -p 22001:8097 -p 22002:22 nvcr.io/nvidia/pytorch:21.07-py3 /bin/bash```

  > - **docker name(ì´ë¦„ ì •ì˜)**: e.g.) cook_video_analysis
  > - **gpu server dir(ë„ì»¤ ê°€ìƒí™˜ê²½ì— ì—°ê²°í•  GPU ì„œë²„ í´ë” ê²½ë¡œ)**: git clone dir(ê¹ƒí´ë¡ í•œ í´ë” ê²½ë¡œë¥¼ ë„£ì–´ì£¼ì„¸ìš”) e.g.) /media/mmlab/hdd3/Cook-Video_Analysis/
  > - **mounted docker dir(ì—°ê²°ëœ ë„ì»¤ í´ë” ê²½ë¡œ)**: e.g.) /workspace/
  > - **port forwading(í¬íŠ¸ ì„¤ì •)**: e.g.) 20000:8888(jupyter), 20001:8097(visdom), 20002:22(ssh)
  > - **docker image(ë„ì»¤ ì´ë¯¸ì§€)**: e.g.) nvcr.io/nvidia/pytorch:21.07-py3
  
  
  
## Inference code


### Input Video, Output Analysis_Result

1. cook_video_analysis.py
  
  ```
  video_tags = cook_video_analysis(module, video_path, fps, db, device, sav=sav, split=split, seg_dir=seg_dir, \
                                   font_text_score=font_text_score, fh_low=fh_low, fh_high=fh_high)
  ```

2. cook_video_analysis_dir.py

  ```
  video_dir_tags = cook_video_analysis_dir(module, video_dir, video_format, result_dir, fps, db, device, \
                                           sav=sav, split=split, font_text_score=font_text_score)
  ```

3. cook_video_analysis_multi_dir.py 

  ```
  video_dir_tags = cook_video_analysis_multi_dir(module, video_dir, video_format, result_dir, fps, db, font_dict, device, \
                                                 sav=sav, split=split, font_text_score=font_text_score)
  ```
  
